var documenterSearchIndex = {"docs":
[{"location":"qiskit/optimizers/#Real-variable-optimizers","page":"-","title":"Real-variable optimizers","text":"","category":"section"},{"location":"qiskit/optimizers/","page":"-","title":"-","text":"Simple, thin wrappers around the SPSA-based optimizers implemented by Qiskit. This optimizers only work on real functions of real variables.","category":"page"},{"location":"qiskit/optimizers/","page":"-","title":"-","text":"Modules = [ComplexSPSA.Qiskit]\nPages = [\"include/qiskit/include/real_optimizers.jl\"]","category":"page"},{"location":"qiskit/optimizers/#Complex-variable-optimizers","page":"-","title":"Complex-variable optimizers","text":"","category":"section"},{"location":"qiskit/optimizers/","page":"-","title":"-","text":"Optimizers which separate the optimization problem of a real function of N complex variables as the equivalent problem of optimizing a real function of 2N real variables, and then solve it by means of the Real-variable optimizers.","category":"page"},{"location":"qiskit/optimizers/","page":"-","title":"-","text":"Modules = [ComplexSPSA.Qiskit]\nPages = [\"include/qiskit/include/complex_optimizers.jl\"]","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Example-1-CSPSA-optimization-of-a-simple-function","page":"Examples","title":"Example 1 - CSPSA optimization of a simple function","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Download file","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Markdown\nMarkdown.parse(\"\"\"\n```julia\n$(read(\"assets/examples/ex01.jl\", String))\n```\n\"\"\")","category":"page"},{"location":"examples/#Example-2-CSPSA-vs-SPSA-on-qubit-tomography-(single-run)","page":"Examples","title":"Example 2 - CSPSA vs SPSA on qubit tomography (single run)","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Download file","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Markdown\nMarkdown.parse(\"\"\"\n```julia\n$(read(\"assets/examples/ex02.jl\", String))\n```\n\"\"\")","category":"page"},{"location":"examples/#Example-3-CSPSA-vs-SPSA-on-qubit-tomography-(multiple-runs)","page":"Examples","title":"Example 3 - CSPSA vs SPSA on qubit tomography (multiple runs)","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Download file","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Markdown\nMarkdown.parse(\"\"\"\n```julia\n$(read(\"assets/examples/ex03.jl\", String))\n```\n\"\"\")","category":"page"},{"location":"examples/#Example-4","page":"Examples","title":"Example 4","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Download file","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Markdown\nMarkdown.parse(\"\"\"\n```julia\n$(read(\"assets/examples/qubit_tomography.jl\", String))\n```\n\"\"\")","category":"page"},{"location":"examples/#Example-5","page":"Examples","title":"Example 5","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Download file","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Markdown\nMarkdown.parse(\"\"\"\n```julia\n$(read(\"assets/examples/ferrie.jl\", String))\n```\n\"\"\")","category":"page"},{"location":"qiskit/intro/#Qiskit-Wrapper","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"","category":"section"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"For purposes of ease of comparison, the ComplexSPSA module includes a Qiskit submodule which wraps some SPSA-based optimizers from the python library Qiskit, and exposes them with an interface common to the rest of the module. The wrappers use the default options as defined by Qiskit for each optimizer.","category":"page"},{"location":"qiskit/intro/#Index-of-optimizers-implemented","page":"Qiskit Wrapper","title":"Index of optimizers implemented","text":"","category":"section"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"Pages = [\"optimizers.md\"]","category":"page"},{"location":"qiskit/intro/#Ensure-julia-can-find-Qiskit","page":"Qiskit Wrapper","title":"Ensure julia can find Qiskit","text":"","category":"section"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"To make sure that julia can find and use the Qiskit library, you can execute the function","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"ComplexSPSA.Qiskit.pip_install_dependencies","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"which is provided by the Qiskit submodule, and may thus be executed as","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"using ComplexSPSA\nComplexSPSA.Qiskit.pip_install_dependencies()","category":"page"},{"location":"qiskit/intro/#Using-the-optimizers","page":"Qiskit Wrapper","title":"Using the optimizers","text":"","category":"section"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"To expose the methods defined on the Qiskit submodule, you can run","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"using ComplexSPSA.Qiskit","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"and then, use the optimizers as","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"x = Qiskit.SPSA(f, guess, Niters)","category":"page"},{"location":"qiskit/intro/","page":"Qiskit Wrapper","title":"Qiskit Wrapper","text":"assuming you have previously defined a valid function, f, initial array of parameters, guess, and number of iterations, Niters.","category":"page"},{"location":"#ComplexSPSA","page":"Introduction","title":"ComplexSPSA","text":"","category":"section"},{"location":"#Description","page":"Introduction","title":"Description","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"A package on Julia for the implementation of stochastic optimizers of real functions on many complex variables, currently under development by Jorge Gidi for the Quantum Information Group from the Universidad de ConcepciÃ³n, Chile.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This package is still on an early stage of development.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"While this package is available on github, it has not (yet) been registered into the Julia ecosystem. Anyways, Julia is capable of cloning, installing and keeping track of this package automatically. To install it, just open a Julia session in a terminal or a Jupyter Notebook, and run","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\npkg\"add https://github.com/jgidi/ComplexSPSA.jl\"","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Assuming the process has ended successfully, ComplexSPSA.jl will be installed and you can now access its functionalities by means of","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using ComplexSPSA","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"and may be updated, as any other package, with","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Pkg\npkg\"update ComplexSPSA\"","category":"page"},{"location":"#About-the-algorithms","page":"Introduction","title":"About the algorithms","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The algorithms hereafter presented are based upon the Simultaneous Perturbation Stochastic Optimization (SPSA) method for real functions of real variables.","category":"page"},{"location":"tools/#Tools","page":"Other tools","title":"Tools","text":"","category":"section"},{"location":"tools/","page":"Other tools","title":"Other tools","text":"Some convenience functions are exposed to the user to solve simple, usual tasks that may appear commonly on the use-cases of this module. Those tools are listed below. ","category":"page"},{"location":"tools/#Index","page":"Other tools","title":"Index","text":"","category":"section"},{"location":"tools/","page":"Other tools","title":"Other tools","text":"Pages = [\"tools.md\"]","category":"page"},{"location":"tools/#Documentation","page":"Other tools","title":"Documentation","text":"","category":"section"},{"location":"tools/","page":"Other tools","title":"Other tools","text":"Modules = [ComplexSPSA]\nPages = [\"include/tools.jl\"]","category":"page"},{"location":"optimizers/#Optimizers","page":"Optimizers","title":"Optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"This package provides an interface to the set optimizers presented in \"Stochastic optimization algorithms for quantum applications\" (Gidi et. al., 2022).","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"In the publication two groups of gain parameters are mentioned:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"The default goup is","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"ComplexSPSA.gains","category":"page"},{"location":"optimizers/#ComplexSPSA.gains","page":"Optimizers","title":"ComplexSPSA.gains","text":"gains = Dict(\n    :a => 3.0,\n    :b => 0.1,\n    :A => 0.0,\n    :s => 0.602,\n    :t => 0.101,\n)\n\nContains the gain parameters used for the optimizers defined within the ComplexSPSA module. By default, the standard gains are used.\n\n\n\n\n\n","category":"constant"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"and the asymptotic gains are also provided as","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"ComplexSPSA.gains_asymptotic","category":"page"},{"location":"optimizers/#ComplexSPSA.gains_asymptotic","page":"Optimizers","title":"ComplexSPSA.gains_asymptotic","text":"gains_asymptotic = Dict(\n    :a => 3.0,\n    :b => 0.1,\n    :A => 0.0,\n    :s => 1.0,\n    :t => 0.166,\n)\n\nDictionary containing the set of asymptotic gain parameters. By default, the standard set of gain parameters are used.\n\n\n\n\n\n","category":"constant"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"The optimizers are subdivided into two categories:","category":"page"},{"location":"optimizers/#First-order-optimizers","page":"Optimizers","title":"First-order optimizers","text":"","category":"section"},{"location":"optimizers/#Options","page":"Optimizers","title":"Options","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Optimizers of this category accept the arguments:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"sign: Specifies if the objective function should be maximized (sign=1) or minimized (sign=-1). Default value is -1.\ninitial_iter: Determines the initial value of the iteration index k.\na, b, A, s and t: The gain parameters. Default values are contained in the dictionary ComplexSPSA.gains.\nlearning_rate_constant: Specifies if the learning rate should be decaying in the iteration number a / (k + A)^s (learning_rate_constant=false) or fixed to a across all iterations (learning_rate_constant=true). Default value is false.\nlearning_rate_Ncalibrate: Integer indicating how many samples to evaluate from the objective function to calibrate the leraning rate a as proposed by Kandala et. al. (2017). Default value is 0 (no calibration).\nblocking: Allows to accept only variable updates which improve the value of the function up to certain tolerance. Default value is false.\nblocking_tol: The tolerance used for blocking. Default value is 0.0.\nblocking_Ncalibrate: Is an integer representing how many evaluations of the function on the seed value should be used to estimate its standard deviation. If blocking_Ncalibrate > 1, then blocking_tol is overriden with the value of twice the standard deviation. The default value of blocking_Ncalibrate is 0.\nresamplings: Dictionary containing the number of samples of the gradient estimator to average at each iteration. It must contain the key \"default\" with the value which will be used for iterations without explicit specification. By default, resamplings = Dict(\"default\" => 1).\npostprocess: A function which takes the array of variables z at the end of each iteration, and returns a postprocessed version of it. The default value is identity, which returns its arguments identically.","category":"page"},{"location":"optimizers/#Optimizers-2","page":"Optimizers","title":"Optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"The optimizers are","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA","page":"Optimizers","title":"ComplexSPSA.SPSA","text":"SPSA(f::Function, guess::AbstractVector{<:Real}, Niters; kwargs...)\n\nFirst order optimizer taking real variables.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA_on_complex","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA_on_complex","page":"Optimizers","title":"ComplexSPSA.SPSA_on_complex","text":"SPSA_on_complex(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nFirst order optimizer taking complex variables. Takes each variable, separate them as a pair of real values, and uses the equivalent real optimizer on them.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA","page":"Optimizers","title":"ComplexSPSA.CSPSA","text":"CSPSA(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nFirst order optimizer taking complex variables\n\n\n\n\n\n","category":"function"},{"location":"optimizers/#Preconditioned-optimizers","page":"Optimizers","title":"Preconditioned optimizers","text":"","category":"section"},{"location":"optimizers/#Options-2","page":"Optimizers","title":"Options","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"All of the options for first-order optimizers, excepting learning_rate_Ncalibrate, may also be provided. Additionally, preconditioned optimizers take the following options:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"initial_hessian: Allows to pass a guess for the initial value of the Hessian estimator. If not given, an Identity matrix is used.\nresamplings: Dictionary containing the number of samples of the gradient estimator to average at each iteration. It must contain the key \"default\" with the value which will be used for iterations without explicit specification. If resamplings[0] is defined, it will be used to compute an estimator as the initial Hessian, overwriting the value possibly provided with initial_hessian. By default, resamplings = Dict(\"default\" => 1).\nhessian_delay: An integer indicating how many iterations should be performed using a first-order optimization rule (while collecting information for the Hessian estimator) before using the Hessian estimator to precondition the gradient estimator. The default value is 0.\na2: Mimics the first-order gain parameter a but for preconditioned iterations. Default value is 1.0. As in the first-order case, the keyword learning_rate_constant may be used to control wether the learning rate should be constant or decaying on the iteration number.\nregularization: A real number indicating the perturbation used on the Hessian regularization. The default value is 0.001.","category":"page"},{"location":"optimizers/#Optimizers-3","page":"Optimizers","title":"Optimizers","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Two categories are mixed within the preconditioned algorithms: Second order and Quantum Natural methods.","category":"page"},{"location":"optimizers/#Second-order","page":"Optimizers","title":"Second order","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Second order methods use additional measurements of the objective function to estimate its Hessian matrix. This methods are:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA2","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA2","page":"Optimizers","title":"ComplexSPSA.SPSA2","text":"SPSA2(f::Function, guess::AbstractVector{<:Real}, Niters; kwargs...)\n\nSecond order optimizer taking complex variables.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA2_on_complex","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA2_on_complex","page":"Optimizers","title":"ComplexSPSA.SPSA2_on_complex","text":"SPSA2_on_complex(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nSecond order optimizer taking complex variables. Takes each variable, separate them as a pair of real values, and uses the equivalent real optimizer on them.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA2","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA2","page":"Optimizers","title":"ComplexSPSA.CSPSA2","text":"CSPSA2(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nSecond order optimizer taking complex variables.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA2_full","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA2_full","page":"Optimizers","title":"ComplexSPSA.CSPSA2_full","text":"CSPSA2_full(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nSecond order optimizer taking complex variables. Does not consider the block-diagonal approximation for the complex Hessian estimator.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA2_scalar","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA2_scalar","page":"Optimizers","title":"ComplexSPSA.SPSA2_scalar","text":"SPSA2_scalar(f::Function, guess::AbstractVector{<:Real}, Niters; kwargs...)\n\nSecond order optimizer taking real variables. Uses a scalar approximation of the Hessian estimator.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA2_scalar_on_complex","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA2_scalar_on_complex","page":"Optimizers","title":"ComplexSPSA.SPSA2_scalar_on_complex","text":"SPSA2_on_complex(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nSecond order optimizer taking complex variables. Uses a scalar approximation of the Hessian estimator. Takes each variable, separate them as a pair of real values, and uses the equivalent real optimizer on them.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA2_scalar","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA2_scalar","page":"Optimizers","title":"ComplexSPSA.CSPSA2_scalar","text":"CSPSA2_scalar(f::Function, guess::AbstractVector, Niters; kwargs...)\n\nSecond order optimizer taking complex variables. Uses a scalar approximation of the Hessian estimator.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/#Quantum-Natural","page":"Optimizers","title":"Quantum Natural","text":"","category":"section"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"Quantum Natural methods, while following a first-order update rule, consider the metric of the problem to precondition the gradient estimate. In particular, the following optimizers require the fidelity $ \\mathscr{fidelity}(z, z')$ to estimate the Fubini-Study metric:","category":"page"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA_QN","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA_QN","page":"Optimizers","title":"ComplexSPSA.SPSA_QN","text":"SPSA_QN(f::Function, fidelity::Function,\n        guess::AbstractVector{<:Real}, Niters; kwargs...)\n\nQuantum Natural optimizer taking real variables.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA_QN_on_complex","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA_QN_on_complex","page":"Optimizers","title":"ComplexSPSA.SPSA_QN_on_complex","text":"SPSA_QN_on_complex(f::Function, fidelity::Function,\n                   guess::AbstractVector, Niters; kwargs...)\n\nQuantum Natural optimizer taking complex variables. Takes each variable, separate them as a pair of real values, and uses the equivalent real optimizer on them.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA_QN","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA_QN","page":"Optimizers","title":"ComplexSPSA.CSPSA_QN","text":" CSPSA_QN(f::Function, fidelity::Function,\n          guess::AbstractVector, Niters; kwargs...)\n\nQuantum Natural optimizer taking complex variables.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA_QN_full","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA_QN_full","page":"Optimizers","title":"ComplexSPSA.CSPSA_QN_full","text":"CSPSA_QN_full(f::Function, fidelity::Function,\n              guess::AbstractVector, Niters; kwargs...)\n\nQuantum Natural optimizer taking complex variables. Does not consider the block-diagonal approximation for the complex Hessian estimator.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA_QN_scalar","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA_QN_scalar","page":"Optimizers","title":"ComplexSPSA.SPSA_QN_scalar","text":"SPSA_QN_scalar(f::Function, fidelity::Function,\n               guess::AbstractVector{<:Real}, Niters; kwargs...)\n\nQuantum Natural optimizer taking real variables. Uses a scalar approximation of the Hessian estimator.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"SPSA_QN_scalar_on_complex","category":"page"},{"location":"optimizers/#ComplexSPSA.SPSA_QN_scalar_on_complex","page":"Optimizers","title":"ComplexSPSA.SPSA_QN_scalar_on_complex","text":"SPSA_QN_scalar_on_complex(f::Function, fidelity::Function,\n                          guess::AbstractVector, Niters; kwargs...)\n\nQuantum Natural optimizer taking complex variables. Uses a scalar approximation of the Hessian estimator. Takes each variable, separate them as a pair of real values, and uses the equivalent real optimizer on them.\n\n\n\n\n\n","category":"function"},{"location":"optimizers/","page":"Optimizers","title":"Optimizers","text":"CSPSA_QN_scalar","category":"page"},{"location":"optimizers/#ComplexSPSA.CSPSA_QN_scalar","page":"Optimizers","title":"ComplexSPSA.CSPSA_QN_scalar","text":"CSPSA_QN_scalar(f::Function, fidelity::Function,\n                guess::AbstractVector, Niters; kwargs...)\n\nQuantum Natural optimizer taking complex variables. Uses a scalar approximation of the Hessian estimator.\n\n\n\n\n\n","category":"function"}]
}
